---
layout: default
---

<h2><a href="/"><span style="text-decoration: underline;">Home</span></a><a href="/assets/pdfs/resume.pdf"><span style="text-decoration: underline; padding:30px">CV</span></a><a href="/teaching.html"><span style="text-decoration: underline;">Teaching</span></a></h2>


<h2>Research Statement</h2>

<h2><b>Job Market Paper</b></h2>

<h3> <a href="https://drive.google.com/file/d/1OLNh06fVi2kfffMgMtbm5_ilNisUHzNF/view?usp=sharing"><span style="text-decoration: underline;">Robust Caliper Tests</span></a></h3>
<div>Caliper tests are widely used to test for the presence of p-hacking and publi- cation bias based on the distribution of the z-statistics across studies. We show that without additional restrictions on the distribution of true effects, Caliper tests may suffer from substantial size distortions. We propose a modification of the existing Caliper test, referred to as the Robust Caliper test, which is shown to control size irrespective of the true effect distribution. We also propose a way of correcting the regression-based version of the Caliper test that allows for the inclusion of additional covariates. The proposed tests are easy to implement and perform well in practice.</div>
<br>

<h2>Publications</h2>

<h3> <a href="https://www.econometricsociety.org/publications/econometrica/2022/03/01/detecting-p-hacking"><span style="text-decoration: underline;">Detecting p-hacking</span></a></h3> with Graham Elliott and Kaspar Wuthrich (Econometrica, 2022)
<div>We theoretically analyze the problem of testing for p‐hacking based on distributions of p‐values across multiple studies. We provide general results for when such distributions have testable restrictions (are non‐increasing) under the null of no p‐hacking. We find novel additional testable restrictions for p‐values based on t‐tests. Specifically, the shape of the power functions results in both complete monotonicity as well as bounds on the distribution of p‐values. These testable restrictions result in more powerful tests for the null hypothesis of no p‐hacking. When there is also publication bias, our tests are joint tests for p‐hacking and publication bias. A reanalysis of two prominent data sets shows the usefulness of our new tests.</div>
<br>
